/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.tajo.engine.planner;

import com.google.common.collect.Lists;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.ContentSummary;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.tajo.algebra.*;
import org.apache.tajo.algebra.CreateTable.ColumnDefinition;
import org.apache.tajo.catalog.*;
import org.apache.tajo.catalog.partition.PartitionDesc;
import org.apache.tajo.catalog.partition.Specifier;
import org.apache.tajo.catalog.proto.CatalogProtos;
import org.apache.tajo.common.TajoDataTypes;
import org.apache.tajo.common.TajoDataTypes.DataType;
import org.apache.tajo.datum.*;
import org.apache.tajo.engine.eval.*;
import org.apache.tajo.engine.exception.InvalidQueryException;
import org.apache.tajo.engine.exception.UndefinedFunctionException;
import org.apache.tajo.engine.exception.VerifyException;
import org.apache.tajo.engine.function.AggFunction;
import org.apache.tajo.engine.function.GeneralFunction;
import org.apache.tajo.engine.planner.LogicalPlan.QueryBlock;
import org.apache.tajo.engine.planner.logical.*;
import org.apache.tajo.engine.utils.SchemaUtil;
import org.apache.tajo.exception.InternalException;
import org.apache.tajo.util.TUtil;
import org.joda.time.DateTime;

import java.util.*;

import static org.apache.tajo.algebra.Aggregation.GroupType;
import static org.apache.tajo.algebra.CreateTable.ColumnPartition;
import static org.apache.tajo.algebra.CreateTable.PartitionType;
import static org.apache.tajo.catalog.proto.CatalogProtos.FunctionType;
import static org.apache.tajo.engine.planner.LogicalPlan.BlockType;

/**
 * This class creates a logical plan from a parse tree ({@link org.apache.tajo.engine.parser.SQLAnalyzer})
 * generated by {@link org.apache.tajo.engine.parser.SQLAnalyzer}.
 *
 * Relational operators can be divided into two categories as follows:
 * <oi>
 *  <li>General operator: this type operators do not affect the tuple schema.
 *  Selection, Sort, and Limit belong to this type.</li>
 *  <li>Projectable operator: this type operators affects the tuple schema.
 *  Scan, Groupby, and Join belong to this type.
 *  </li>
 * </oi>
 */
public class LogicalPlanner extends BaseAlgebraVisitor<LogicalPlanner.PlanContext, LogicalNode> {
  private static Log LOG = LogFactory.getLog(LogicalPlanner.class);
  private final CatalogService catalog;

  public LogicalPlanner(CatalogService catalog) {
    this.catalog = catalog;
  }

  public class PlanContext {
    LogicalPlan plan;
    QueryBlock block;

    public PlanContext(LogicalPlan plan, QueryBlock block) {
      this.plan = plan;
      this.block = block;
      this.block.evalLists = new EvalExprManager(plan, LogicalPlanner.this, block);
    }
  }

  /**
   * This generates a logical plan.
   *
   * @param expr A relational algebraic expression for a query.
   * @return A logical plan
   */
  public LogicalPlan createPlan(Expr expr) throws PlanningException {

    LogicalPlan plan = new LogicalPlan(this);
    LogicalNode subroot;

    Stack<Expr> stack = new Stack<Expr>();

    QueryBlock rootBlock = plan.newAndGetBlock(LogicalPlan.ROOT_BLOCK);
    PlanContext context = new PlanContext(plan, rootBlock);
    subroot = visit(context, stack, expr);

    LogicalRootNode root = new LogicalRootNode(plan.newPID());
    root.setInSchema(subroot.getOutSchema());
    root.setOutSchema(subroot.getOutSchema());
    root.setChild(subroot);
    plan.getRootBlock().setRoot(root);

    return plan;
  }

  public void preHook(PlanContext context, Stack<Expr> stack, Expr expr) {
    context.block = checkIfNewBlockOrGet(context.plan, context.block.getName());
    context.block.setAlgebraicExpr(expr);
  }

  public LogicalNode postHook(PlanContext context, Stack<Expr> stack, Expr expr, LogicalNode current)
      throws PlanningException {
    // Post work
    if ((expr.getType() == OpType.RelationList && ((RelationList) expr).size() == 1)
        || expr.getType() == OpType.Having) {
      return current;
    }

    // mark the node as the visited node and do post work for each operator
    context.block.postVisit(current, stack);

    return current;
  }

  /**
   * It checks if the first node in this query block. If not, it creates and adds a new query block.
   * In addition, it always returns the query block corresponding to the block name.
   */
  private QueryBlock checkIfNewBlockOrGet(LogicalPlan plan, String blockName) {
    QueryBlock block = plan.getBlock(blockName);
    if (block == null) {
      return plan.newAndGetBlock(blockName);
    } else {
      return block;
    }
  }

  public TableSubQueryNode visitTableSubQuery(PlanContext context, Stack<Expr> stack, TablePrimarySubQuery expr)
      throws PlanningException {
    QueryBlock newBlock = context.plan.newAndGetBlock(expr.getName());
    PlanContext newContext = new PlanContext(context.plan, newBlock);
    Stack<Expr> newStack = new Stack<Expr>();
    LogicalNode child = visit(newContext, newStack, expr.getSubQuery());
    context.plan.connectBlocks(newContext.block, context.block, BlockType.TableSubQuery);
    return new TableSubQueryNode(context.plan.newPID(), expr.getName(), child);
  }


  @Override
  public ScanNode visitRelation(PlanContext context, Stack<Expr> stack, Relation expr)
      throws PlanningException {
    // 1. init phase

    // 2. build child plans
    // 3. build scan plan
    Relation relation = expr;
    TableDesc desc = catalog.getTableDesc(relation.getName());
    if (!desc.hasStats()) {
      updatePhysicalInfo(desc);
    }

    ScanNode scanNode;
    if (relation.hasAlias()) {
      scanNode = new ScanNode(context.plan.newPID(), desc, relation.getAlias());
    } else {
      scanNode = new ScanNode(context.plan.newPID(), desc);
    }

    context.block.addRelation(scanNode);

    // set targets
    Set<Target> evaluatedTargets = new LinkedHashSet<Target>();
    for (TargetExpr rawTarget : context.block.evalLists.getRawTargets()) {
      try {
        EvalNode evalNode = createEvalTree(context.plan, context.block, rawTarget.getExpr());
        if (PlannerUtil.canBeEvaluated(evalNode, scanNode) && EvalTreeUtil.findDistinctAggFunction(evalNode).size() == 0) {
          context.block.evalLists.switchTarget(rawTarget.getAlias(), evalNode);
          evaluatedTargets.add(new Target(evalNode, rawTarget.getAlias()));
        }
      } catch (VerifyException ve) {
      }
    }

    List<Target> targets = new ArrayList<Target>();
    for (Column column : scanNode.getInSchema().getColumns()) {
      outer:
      for (String targetName : context.block.evalLists.getTargetNames()) {
        if (column.getQualifiedName().equals(targetName)) {
          continue outer;
        }
      }
      targets.add(new Target(new FieldEval(column)));
    }

    targets.addAll(evaluatedTargets);

    scanNode.setTargets(targets.toArray(new Target[targets.size()]));
    scanNode.setOutSchema(PlannerUtil.targetToSchema(scanNode.getTargets()));

    return scanNode;
  }

  private void updatePhysicalInfo(TableDesc desc) {
    if (desc.getPath() != null) {
      try {
        FileSystem fs = desc.getPath().getFileSystem(new Configuration());
        FileStatus status = fs.getFileStatus(desc.getPath());
        if (desc.getStats() != null && (status.isDirectory() || status.isFile())) {
          ContentSummary summary = fs.getContentSummary(desc.getPath());
          if (summary != null) {
            long volume = summary.getLength();
            desc.getStats().setNumBytes(volume);
          }
        }
      } catch (Throwable t) {
        LOG.warn(t);
      }
    }
  }

  /*===============================================================================================
    JOIN SECTION
   ===============================================================================================*/
  @Override
  public LogicalNode visitRelationList(PlanContext context, Stack<Expr> stack, RelationList relations)
      throws PlanningException {

    LogicalNode current = visit(context, stack, relations.getRelations()[0]);

    LogicalNode left;
    LogicalNode right;
    if (relations.size() > 1) {

      for (int i = 1; i < relations.size(); i++) {
        left = current;
        right = visit(context, stack, relations.getRelations()[i]);
        current = createCatasianProduct(context.plan, left, right);
      }
    }

    return current;
  }

  @Override
  public LogicalNode visitJoin(PlanContext context, Stack<Expr> stack, Join join)
      throws PlanningException {
    // Phase 1: Init
    LogicalPlan plan = context.plan;
    QueryBlock block = context.block;

    // Phase 2: build child plans
    stack.push(join);
    LogicalNode left = visit(context, stack, join.getLeft());
    LogicalNode right = visit(context, stack, join.getRight());
    stack.pop();

    // Phase 3: build this plan
    JoinNode joinNode = new JoinNode(plan.newPID(), join.getJoinType(), left, right);

    // Set A merged input schema
    Schema merged;
    if (join.isNatural()) {
      merged = getNaturalJoin(left, right);
    } else {
      merged = SchemaUtil.merge(left.getOutSchema(), right.getOutSchema());
    }
    joinNode.setInSchema(merged);
    joinNode.setOutSchema(merged);

    // Determine join conditions
    if (join.isNatural()) { // if natural join, it should have the equi-join conditions by common column names
      Schema leftSchema = joinNode.getLeftChild().getInSchema();
      Schema rightSchema = joinNode.getRightChild().getInSchema();
      Schema commons = SchemaUtil.getCommons(leftSchema, rightSchema);
      EvalNode njCond = getNaturalJoinCondition(leftSchema, rightSchema, commons);
      joinNode.setJoinQual(njCond);
    } else if (join.hasQual()) { // otherwise, the given join conditions are set
      joinNode.setJoinQual(createEvalTree(plan, block, join.getQual()));
    }

    return joinNode;
  }

  private static EvalNode getNaturalJoinCondition(Schema outer, Schema inner, Schema commons) {
    EvalNode njQual = null;
    EvalNode equiQual;

    Column leftJoinKey;
    Column rightJoinKey;
    for (Column common : commons.getColumns()) {
      leftJoinKey = outer.getColumnByName(common.getColumnName());
      rightJoinKey = inner.getColumnByName(common.getColumnName());
      equiQual = new BinaryEval(EvalType.EQUAL,
          new FieldEval(leftJoinKey), new FieldEval(rightJoinKey));
      if (njQual == null) {
        njQual = equiQual;
      } else {
        njQual = new BinaryEval(EvalType.AND,
            njQual, equiQual);
      }
    }

    return njQual;
  }

  private static LogicalNode createCatasianProduct(LogicalPlan plan, LogicalNode left, LogicalNode right) {
    JoinNode join = new JoinNode(plan.newPID(), JoinType.CROSS, left, right);
    Schema joinSchema = SchemaUtil.merge(
        join.getLeftChild().getOutSchema(),
        join.getRightChild().getOutSchema());
    join.setInSchema(joinSchema);
    join.setOutSchema(joinSchema);

    return join;
  }

  private static Schema getNaturalJoin(LogicalNode outer, LogicalNode inner) {
    Schema joinSchema = new Schema();
    Schema commons = SchemaUtil.getCommons(outer.getOutSchema(),
        inner.getOutSchema());
    joinSchema.addColumns(commons);
    for (Column c : outer.getOutSchema().getColumns()) {
      for (Column common : commons.getColumns()) {
        if (!common.getColumnName().equals(c.getColumnName())) {
          joinSchema.addColumn(c);
        }
      }
    }

    for (Column c : inner.getOutSchema().getColumns()) {
      for (Column common : commons.getColumns()) {
        if (!common.getColumnName().equals(c.getColumnName())) {
          joinSchema.addColumn(c);
        }
      }
    }
    return joinSchema;
  }

  /*===============================================================================================
    SET OPERATION SECTION
   ===============================================================================================*/

  @Override
  public LogicalNode visitUnion(PlanContext context, Stack<Expr> stack, SetOperation setOperation)
      throws PlanningException {
    return buildSetPlan(context, stack, setOperation);
  }

  @Override
  public LogicalNode visitExcept(PlanContext context, Stack<Expr> stack, SetOperation setOperation)
      throws PlanningException {
    return buildSetPlan(context, stack, setOperation);
  }

  @Override
  public LogicalNode visitIntersect(PlanContext context, Stack<Expr> stack, SetOperation setOperation)
      throws PlanningException {
    return buildSetPlan(context, stack, setOperation);
  }

  private LogicalNode buildSetPlan(PlanContext context, Stack<Expr> stack, SetOperation setOperation)
      throws PlanningException {

    // 1. Init Phase
    LogicalPlan plan = context.plan;
    QueryBlock block = context.block;

    // 2. Build Child Plans
    PlanContext leftContext = new PlanContext(plan, plan.newNoNameBlock());
    Stack<Expr> leftStack = new Stack<Expr>();
    LogicalNode left = visit(leftContext, leftStack, setOperation.getLeft());
    TableSubQueryNode leftSubQuery = new TableSubQueryNode(plan.newPID(), leftContext.block.getName(), left);
    context.plan.connectBlocks(leftContext.block, context.block, BlockType.TableSubQuery);

    PlanContext rightContext = new PlanContext(plan, plan.newNoNameBlock());
    Stack<Expr> rightStack = new Stack<Expr>();
    LogicalNode right = visit(rightContext, rightStack, setOperation.getRight());
    TableSubQueryNode rightSubQuery = new TableSubQueryNode(plan.newPID(), rightContext.block.getName(), right);
    context.plan.connectBlocks(rightContext.block, context.block, BlockType.TableSubQuery);

    BinaryNode setOp;
    if (setOperation.getType() == OpType.Union) {
      setOp = new UnionNode(plan.newPID(), leftSubQuery, rightSubQuery);
    } else if (setOperation.getType() == OpType.Except) {
      setOp = new ExceptNode(plan.newPID(), leftSubQuery, rightSubQuery);
    } else if (setOperation.getType() == OpType.Intersect) {
      setOp = new IntersectNode(plan.newPID(), leftSubQuery, rightSubQuery);
    } else {
      throw new VerifyException("Invalid Type: " + setOperation.getType());
    }

    // Strip the table names from the targets of the both blocks
    // in order to check the equivalence the schemas of both blocks.
    Target [] leftStrippedTargets = PlannerUtil.stripTarget(leftContext.block.getCurrentTargets());

    Schema outSchema = PlannerUtil.targetToSchema(leftStrippedTargets);
    setOp.setInSchema(leftSubQuery.getOutSchema());
    setOp.setOutSchema(outSchema);

    if (isNoUpperProjection(stack)) {
      block.evalLists = new EvalExprManager(plan, this, leftContext.block);
//      block.targetListManager.resolveAll();
//      block.setSchema(block.targetListManager.getUpdatedSchema());
    }

    return setOp;
  }

  @Override
  public SelectionNode visitFilter(PlanContext context, Stack<Expr> stack, Selection selection)
      throws PlanningException {
    // 1. init phase:
    LogicalPlan plan = context.plan;
    QueryBlock block = context.block;

    String qualName = context.block.evalLists.addExpr(selection.getQual());

    // 2. build child plans:
    stack.push(selection);
    LogicalNode child = visit(context, stack, selection.getChild());
    stack.pop();

    Target target = context.block.evalLists.getTarget(qualName);
    EvalNode evalNode;
    if (target == null) {
      evalNode = createEvalTree(plan, block, selection.getQual());
      block.evalLists.switchTarget(qualName, evalNode);
    } else {
      evalNode = target.getEvalTree();
    }
    // 3. build this plan:
    EvalNode searchCondition = evalNode;
    EvalNode simplified = AlgebraicUtil.eliminateConstantExprs(searchCondition);
    SelectionNode selectionNode = new SelectionNode(plan.newPID(), simplified);

    // 4. set child plan, update input/output schemas:
    selectionNode.setChild(child);
    selectionNode.setInSchema(child.getOutSchema());
    selectionNode.setOutSchema(child.getOutSchema());

    // 5. update block information:
    block.setSelectionNode(selectionNode);

    return selectionNode;
  }

  /*===============================================================================================
    GROUP BY SECTION
   ===============================================================================================*/

  @Override
  public LogicalNode visitGroupBy(PlanContext context, Stack<Expr> stack, Aggregation aggregation)
      throws PlanningException {

    // Initialization Phase:
    LogicalPlan plan = context.plan;
    QueryBlock block = context.block;

    String [] groupingSets = block.evalLists.addExprArray(aggregation.getGroupSet()[0].getGroupingSets());

    // 2. Build Child Plan Phase:
    stack.push(aggregation);
    LogicalNode child = visit(context, stack, aggregation.getChild());
    stack.pop();

    Set<Target> evaluatedTargets = new LinkedHashSet<Target>();
    for (TargetExpr rawTarget : context.block.evalLists.getRawTargets()) {
      try {
        EvalNode evalNode = createEvalTree(context.plan, context.block, rawTarget.getExpr());
        if (EvalTreeUtil.findDistinctAggFunction(evalNode).size() > 0) {
          context.block.evalLists.switchTarget(rawTarget.getAlias(), evalNode);
          evaluatedTargets.add(new Target(evalNode, rawTarget.getAlias()));
        }
      } catch (VerifyException ve) {
      }
    }

    // 3. Build This Plan:
    Aggregation.GroupElement [] groupElements = aggregation.getGroupSet();

    if (groupElements[0].getType() == GroupType.OrdinaryGroup) { // for group-by
      Column [] groupingColumns = new Column[aggregation.getGroupSet()[0].getGroupingSets().length];
      for (int i = 0; i < groupingColumns.length; i++) {
        if (block.evalLists.isResolved(groupingSets[i])) {
          groupingColumns[i] = block.evalLists.getTarget(groupingSets[i]).getColumnSchema();
        } else {

        }
      }

      GroupbyNode groupingNode = new GroupbyNode(plan.newPID(), groupingColumns);
      if (aggregation.hasHavingCondition()) {
        groupingNode.setHavingCondition(
            createEvalTree(plan, block, aggregation.getHavingCondition()));
      }

      List<Target> targets = new ArrayList<Target>();

      for (Column column : groupingColumns) {
        if (child.getOutSchema().contains(column)) {
          targets.add(new Target(new FieldEval(child.getOutSchema().getColumn(column))));
        }
      }
      targets.addAll(evaluatedTargets);
      groupingNode.setTargets(targets.toArray(new Target[targets.size()]));
      // 4. Set Child Plan and Update Input Schemes Phase
      groupingNode.setChild(child);
      block.setGroupbyNode(groupingNode);
      groupingNode.setInSchema(child.getOutSchema());
      groupingNode.setOutSchema(PlannerUtil.targetToSchema(groupingNode.getTargets()));

      // 5. Update Output Schema and Targets for Upper Plan

      return groupingNode;

    } else {
      throw new InvalidQueryException("Not support grouping");
    }
  }

  public static final Column[] ALL= Lists.newArrayList().toArray(new Column[0]);

  public static List<Column[]> generateCuboids(Column[] columns) {
    int numCuboids = (int) Math.pow(2, columns.length);
    int maxBits = columns.length;

    List<Column[]> cube = Lists.newArrayList();
    List<Column> cuboidCols;

    cube.add(ALL);
    for (int cuboidId = 1; cuboidId < numCuboids; cuboidId++) {
      cuboidCols = Lists.newArrayList();
      for (int j = 0; j < maxBits; j++) {
        int bit = 1 << j;
        if ((cuboidId & bit) == bit) {
          cuboidCols.add(columns[j]);
        }
      }
      cube.add(cuboidCols.toArray(new Column[cuboidCols.size()]));
    }
    return cube;
  }

  /*===============================================================================================
    SORT SECTION
   ===============================================================================================*/

  @Override
  public SortNode visitSort(PlanContext context, Stack<Expr> stack, Sort sort) throws PlanningException {
    int sortKeyNum = sort.getSortSpecs().length;
    Sort.SortSpec[] sortSpecs = sort.getSortSpecs();
    String [] sortKeyNames = new String[sortKeyNum];

    for (int i = 0; i < sortKeyNum; i++) {
      sortKeyNames[i] = context.block.evalLists.addExpr(sortSpecs[i].getKey());
    }

    // 2. Build Child Plans:
    stack.push(sort);
    LogicalNode child = visit(context, stack, sort.getChild());
    //child = insertGroupbyNodeIfUnresolved(plan, block, child, stack);
    stack.pop();

    // 3. Build this plan:
    SortSpec[] annotatedSortSpecs = new SortSpec[sortKeyNum];
    Column column = null;
    for (int i = 0; i < sort.getSortSpecs().length; i++) {
      if (context.block.evalLists.isResolved(sortKeyNames[i])) {
        column = context.block.evalLists.getTarget(sortKeyNames[i]).getColumnSchema();
      }
      annotatedSortSpecs[i] = new SortSpec(column, sortSpecs[i].isAscending(), sortSpecs[i].isNullFirst());
    }
    SortNode sortNode = new SortNode(context.plan.newPID(), annotatedSortSpecs);

    // 4. Set Child Plan, Update Input/Output Schemas:
    sortNode.setChild(child);
    sortNode.setInSchema(child.getOutSchema());
    sortNode.setOutSchema(child.getOutSchema());

    return sortNode;
  }

  @Override
  public LimitNode visitLimit(PlanContext context, Stack<Expr> stack, Limit limit) throws PlanningException {
    // 1. Init Phase:
    LogicalPlan plan = context.plan;
    QueryBlock block = context.block;

    // build child plans
    stack.push(limit);
    LogicalNode child = visit(context, stack, limit.getChild());
    stack.pop();

    // build limit plan
    EvalNode firstFetchNum = createEvalTree(plan, block, limit.getFetchFirstNum());
    firstFetchNum.eval(null, null, null);
    LimitNode limitNode = new LimitNode(context.plan.newPID(), firstFetchNum.terminate(null).asInt8());

    // set child plan and update input/output schemas.
    limitNode.setChild(child);
    limitNode.setInSchema(child.getOutSchema());
    limitNode.setOutSchema(child.getOutSchema());
    return limitNode;
  }

  /*===============================================================================================
    PROJECTION SECTION
   ===============================================================================================*/


  private static boolean existsAggregationFunction(Expr expr) throws PlanningException {
    AggregationFunctionFinder finder = new AggregationFunctionFinder();
    AggFunctionFoundResult result = new AggFunctionFoundResult();
    finder.visit(result, new Stack<Expr>(), expr);
    return result.found;
  }

  static class AggFunctionFoundResult {
    boolean found;
  }
  static class AggregationFunctionFinder extends SimpleAlgebraVisitor<AggFunctionFoundResult> {
    @Override
    public Expr visitCountRowsFunction(AggFunctionFoundResult ctx, Stack<Expr> stack, CountRowsFunctionExpr expr)
        throws PlanningException {
      ctx.found = true;
      return super.visitCountRowsFunction(ctx, stack, expr);
    }

    @Override
    public Expr visitGeneralSetFunction(AggFunctionFoundResult ctx, Stack<Expr> stack, GeneralSetFunctionExpr expr)
        throws PlanningException {
      ctx.found = true;
      return super.visitGeneralSetFunction(ctx, stack, expr);
    }
  }

  @Override
  public LogicalNode visitProjection(PlanContext context, Stack<Expr> stack, Projection projection)
      throws PlanningException {

    //1: init Phase
    LogicalPlan plan = context.plan;
    QueryBlock block = context.block;

    String [] targetNames = new String[projection.size()];
    if (!projection.isAllProjected()) {
      block.evalLists = new EvalExprManager(plan, this, context.block);
      DissectedExpr dissectedExpr = null;
      TargetExpr rawTarget;
      for (int i = 0; i < projection.getTargets().length; i++) {
        rawTarget = projection.getTargets()[i];

        if (existsAggregationFunction(rawTarget)) {
          block.setHasGrouping();
        }

        // dissect an expression into more parts (at most dissected into three parts)
        dissectedExpr = dissectedExpr(plan, rawTarget.getExpr());

        // Get all projecting references
        if (rawTarget.hasAlias()) {
          targetNames[i] = block.evalLists.addTargetExpr(new TargetExpr(dissectedExpr.outer, rawTarget.getAlias()));
        } else {
          targetNames[i] = block.evalLists.addExpr(dissectedExpr.outer);
        }

        // Add sub-expressions from dissected parts.
        block.evalLists.addTargetExprArray(dissectedExpr.aggregation);
        block.evalLists.addTargetExprArray(dissectedExpr.inner);
      }
    }

    // When a select statement with from clause is given
    if (!projection.hasChild()) {
      EvalExprNode evalOnly = new EvalExprNode(context.plan.newPID(), annotateTargets(plan, block,
          projection.getTargets()));
      evalOnly.setOutSchema(getProjectedSchema(plan, evalOnly.getExprs()));
      block.setProjectionNode(evalOnly);
      return evalOnly;
    }

    // Build Child Plans
    stack.push(projection);
    LogicalNode child = visit(context, stack, projection.getChild());
    // check if it is aggregation query without group-by clause. If so, it inserts group-by node to its child.
    child = insertGroupbyNodeIfUnresolved(plan, block, child, targetNames, stack);
    stack.pop();

    if (projection.isDistinct() && block.hasGrouping()) {
      throw new VerifyException("Cannot support grouping and distinct at the same time");
    } else {
      if (projection.isDistinct()) {
        Schema outSchema = child.getOutSchema();
        GroupbyNode dupRemoval = new GroupbyNode(plan.newPID(), outSchema.toArray());
        dupRemoval.setTargets(PlannerUtil.schemaToTargets(outSchema));
        dupRemoval.setInSchema(outSchema);
        dupRemoval.setOutSchema(outSchema);
        dupRemoval.setChild(child);
        child = dupRemoval;
      }
    }

    ProjectionNode projectionNode;
    Target [] targets;
    if (projection.isAllProjected()) {
      targets = PlannerUtil.schemaToTargets(child.getOutSchema());
    } else {
      targets = buildTargets(plan, block, targetNames);
    }
    projectionNode = new ProjectionNode(context.plan.newPID(), targets);
    projectionNode.setOutSchema(getProjectedSchema(plan, projectionNode.getTargets()));
    projectionNode.setInSchema(child.getOutSchema());
    projectionNode.setChild(child);
    block.setProjectionNode(projectionNode);

    return projectionNode;
  }

  private Target [] buildTargets(LogicalPlan plan, QueryBlock block, String[] referenceNames)
      throws PlanningException {
    Target [] targets = new Target[referenceNames.length];
    for (int i = 0; i < referenceNames.length; i++) {
      if (block.evalLists.isResolved(referenceNames[i])) {
        targets[i] = block.evalLists.getTarget(referenceNames[i]);
      } else {
        EvalNode evalNode = createEvalTree(plan, block,
            block.evalLists.getRawTarget(referenceNames[i]).getExpr());
        targets[i] = new Target(evalNode, referenceNames[i]);
        block.evalLists.switchTarget(referenceNames[i], evalNode);
      }
    }
    return targets;
  }

  class DissectedExpr {
    LogicalPlan plan;
    Expr outer;
    List<TargetExpr> aggregation = new ArrayList<TargetExpr>();
    List<TargetExpr> inner = new ArrayList<TargetExpr>();

    DissectedExpr(LogicalPlan plan) {
      this.plan = plan;
    }
  }

  DissectedExpr dissectedExpr(LogicalPlan plan, Expr expr) throws PlanningException {
    DissectedExprVisitor visitor = new DissectedExprVisitor();
    DissectedExpr dissectedExpr = new DissectedExpr(plan);

    // early pruning
    if (expr.getType() == OpType.Column || expr.getType() == OpType.Literal || expr.getType() == OpType.NullLiteral) {
      dissectedExpr.outer = expr;
    } else {
      visitor.visit(dissectedExpr, new Stack<Expr>(), expr);
    }

    return dissectedExpr;
  }

  private class DissectedExprVisitor extends SimpleAlgebraVisitor<DissectedExpr> {

    /**
     * The posthook is called before each expression is visited.
     */
    public Expr postHook(DissectedExpr ctx, Stack<Expr> stack, Expr expr, Expr current) throws PlanningException {
      ctx.outer = expr;
      return current;
    }

    private boolean isAggregationFunction(Expr expr) {
      return expr.getType() == OpType.GeneralSetFunction || expr.getType() == OpType.CountRowsFunction;
    }

    @Override
    public Expr visitCaseWhen(DissectedExpr ctx, Stack<Expr> stack, CaseWhenPredicate expr) throws PlanningException {
      stack.push(expr);
      for (CaseWhenPredicate.WhenExpr when : expr.getWhens()) {
        if (isAggregationFunction(when.getCondition())) {
          String referenceName = ctx.plan.newGneratedColumnName(when.getCondition());
          ctx.aggregation.add(new TargetExpr(when.getCondition(), referenceName));
          when.setCondition(new ColumnReferenceExpr(referenceName));
        }
        if (isAggregationFunction(when.getResult())) {
          String referenceName = ctx.plan.newGneratedColumnName(when.getResult());
          ctx.aggregation.add(new TargetExpr(when.getResult(), referenceName));
          when.setResult(new ColumnReferenceExpr(referenceName));
        }
      }
      if (expr.hasElseResult()) {
        if (isAggregationFunction(expr.getElseResult())) {
          String referenceName = ctx.plan.newGneratedColumnName(expr.getElseResult());
          ctx.aggregation.add(new TargetExpr(expr.getElseResult(), referenceName));
          expr.setElseResult(new ColumnReferenceExpr(referenceName));
        }
      }
      stack.pop();
      return expr;
    }

    @Override
    public Expr visitUnaryOperator(DissectedExpr ctx, Stack<Expr> stack, UnaryOperator expr) throws PlanningException {
      super.visitUnaryOperator(ctx, stack, expr);
      if (isAggregationFunction(expr.getChild())) {
        // Get an anonymous column name and replace the aggregation function by the column name
        String refName = ctx.plan.newGneratedColumnName(expr.getChild());
        ctx.aggregation.add(new TargetExpr(expr.getChild(), refName));
        expr.setChild(new ColumnReferenceExpr(refName));
      }

      return expr;
    }

    @Override
    public Expr visitBinaryOperator(DissectedExpr ctx, Stack<Expr> stack, BinaryOperator expr) throws PlanningException {
      super.visitBinaryOperator(ctx, stack, expr);

      ////////////////////////
      // For Left Term
      ////////////////////////

      if (isAggregationFunction(expr.getLeft())) {
        String leftRefName = ctx.plan.newGneratedColumnName(expr.getLeft());
        ctx.aggregation.add(new TargetExpr(expr.getLeft(), leftRefName));
        expr.setLeft(new ColumnReferenceExpr(leftRefName));
      }


      ////////////////////////
      // For Right Term
      ////////////////////////
      if (isAggregationFunction(expr.getRight())) {
        String rightRefName = ctx.plan.newGneratedColumnName(expr.getRight());
        ctx.aggregation.add(new TargetExpr(expr.getRight(), rightRefName));
        expr.setRight(new ColumnReferenceExpr(rightRefName));
      }

      return expr;
    }

    ///////////////////////////////////////////////////////////////////////////////////////////////////////////
    // Function Section
    ///////////////////////////////////////////////////////////////////////////////////////////////////////////

    @Override
    public Expr visitFunction(DissectedExpr ctx, Stack<Expr> stack, FunctionExpr expr) throws PlanningException {
      stack.push(expr);

      Expr param;
      for (int i = 0; i < expr.getParams().length; i++) {
        param = expr.getParams()[i];
        visit(ctx, stack, param);

        if (isAggregationFunction(param)) {
          String referenceName = ctx.plan.newGneratedColumnName(param);
          ctx.aggregation.add(new TargetExpr(param, referenceName));
          expr.getParams()[i] = new ColumnReferenceExpr(referenceName);
        }
      }

      stack.pop();

      return expr;
    }

    @Override
    public Expr visitGeneralSetFunction(DissectedExpr ctx, Stack<Expr> stack, GeneralSetFunctionExpr expr)
        throws PlanningException {
      stack.push(expr);

      Expr param;
      for (int i = 0; i < expr.getParams().length; i++) {
        param = expr.getParams()[i];
        visit(ctx, stack, param);

        String referenceName = ctx.plan.newGneratedColumnName(param);
        ctx.inner.add(new TargetExpr(param, referenceName));
        expr.getParams()[i] = new ColumnReferenceExpr(referenceName);
      }
      stack.pop();
      return expr;
    }

    ///////////////////////////////////////////////////////////////////////////////////////////////////////////
    // Literal Section
    ///////////////////////////////////////////////////////////////////////////////////////////////////////////

    @Override
    public Expr visitCastExpr(DissectedExpr ctx, Stack<Expr> stack, CastExpr expr) throws PlanningException {
      super.visitCastExpr(ctx, stack, expr);
      if (expr.getChild().getType() == OpType.GeneralSetFunction
          || expr.getChild().getType() == OpType.CountRowsFunction) {
        String referenceName = ctx.plan.newGneratedColumnName(expr.getChild());
        ctx.aggregation.add(new TargetExpr(expr.getChild(), referenceName));
        expr.setChild(new ColumnReferenceExpr(referenceName));
      }
      return expr;
    }
  }


  /**
   * Insert a group-by operator before a sort or a projection operator.
   * It is used only when a group-by clause is not given.
   */
  private LogicalNode insertGroupbyNodeIfUnresolved(LogicalPlan plan, QueryBlock block,
                                                    LogicalNode child, String [] targetNames,
                                                    Stack<Expr> stack) throws PlanningException {

    if (!block.isGroupingResolved()) {
      GroupbyNode groupbyNode = new GroupbyNode(plan.newPID(), new Column[] {});
      Target [] targets = new Target[block.getProjection().size()];
      for (int i = 0; i < block.getProjection().size(); i++) {
        targets[i] = block.evalLists.getTarget(targetNames[i]);
        if (targets[i] == null) {
          EvalNode evalNode = createEvalTree(plan, block, block.evalLists.getRawTarget(targetNames[i]).getExpr());
          targets[i] = new Target(evalNode, targetNames[i]);
          block.evalLists.switchTarget(targetNames[i], targets[i].getEvalTree());
        }
      }
      groupbyNode.setTargets(targets);
      groupbyNode.setChild(child);
      groupbyNode.setInSchema(child.getOutSchema());
      groupbyNode.setOutSchema(PlannerUtil.targetToSchema(targets));

      block.postVisit(groupbyNode, stack);
      return groupbyNode;
    } else {
      return child;
    }
  }

  private boolean isNoUpperProjection(Stack<Expr> stack) {
    for (Expr expr : stack) {
      OpType type = expr.getType();
      if (!( (type == OpType.Projection) || (type == OpType.Aggregation) || (type == OpType.Join) )) {
        return false;
      }
    }

    return true;
  }

  /*===============================================================================================
    Data Definition Language (DDL) SECTION
   ===============================================================================================*/

  @Override
  public LogicalNode visitCreateTable(PlanContext context, Stack<Expr> stack, CreateTable expr)
      throws PlanningException {

    String tableName = expr.getTableName();

    if (expr.hasSubQuery()) {
      stack.add(expr);
      LogicalNode subQuery = visit(context, stack, expr.getSubQuery());
      stack.pop();
      StoreTableNode storeNode = new StoreTableNode(context.plan.newPID(), tableName);
      storeNode.setCreateTable();
      storeNode.setChild(subQuery);

      storeNode.setInSchema(subQuery.getOutSchema());
      if(!expr.hasTableElements()) {
        // CREATE TABLE tbl AS SELECT ...
        expr.setTableElements(convertSchemaToTableElements(subQuery.getOutSchema()));
      }
      // else CREATE TABLE tbl(col1 type, col2 type) AS SELECT ...
      storeNode.setOutSchema(convertTableElementsSchema(expr.getTableElements()));

      if (expr.hasStorageType()) {
        storeNode.setStorageType(CatalogUtil.getStoreType(expr.getStorageType()));
      } else {
        // default type
        storeNode.setStorageType(CatalogProtos.StoreType.CSV);
      }

      if (expr.hasParams()) {
        Options options = new Options();
        options.putAll(expr.getParams());
        storeNode.setOptions(options);
      }

      if (expr.hasPartition()) {
        storeNode.setPartitions(convertTableElementsPartition(context, expr));
      }

      return storeNode;
    } else {
      Schema tableSchema;
      boolean mergedPartition = false;
      if (expr.hasPartition()) {
        if (expr.getPartition().getPartitionType().equals(PartitionType.COLUMN)) {
          if (((ColumnPartition)expr.getPartition()).isOmitValues()) {
            mergedPartition = true;
          }
        } else {
          throw new PlanningException(String.format("Not supported PartitonType: %s", 
                                      expr.getPartition().getPartitionType()));
        }
      }

      if (mergedPartition) {
        ColumnDefinition [] merged = TUtil.concat(expr.getTableElements(),
                          ((ColumnPartition)expr.getPartition()).getColumns());
        tableSchema = convertTableElementsSchema(merged);
      } else {
        tableSchema = convertTableElementsSchema(expr.getTableElements());
      }

      CreateTableNode createTableNode = new CreateTableNode(
          context.plan.newPID(),
          expr.getTableName(),
          tableSchema);

      if (expr.isExternal()) {
        createTableNode.setExternal(true);
      }

      if (expr.hasStorageType()) {
        createTableNode.setStorageType(CatalogUtil.getStoreType(expr.getStorageType()));
      } else {
        // default type
        // TODO - it should be configurable.
        createTableNode.setStorageType(CatalogProtos.StoreType.CSV);
      }

      if (expr.hasParams()) {
        Options options = new Options();
        options.putAll(expr.getParams());
        createTableNode.setOptions(options);
      }

      if (expr.hasLocation()) {
        createTableNode.setPath(new Path(expr.getLocation()));
      }

      if (expr.hasPartition()) { 
        if (expr.getPartition().getPartitionType().equals(PartitionType.COLUMN)) {
          createTableNode.setPartitions(convertTableElementsPartition(context, expr));
        } else {
          throw new PlanningException(String.format("Not supported PartitonType: %s", 
                                      expr.getPartition().getPartitionType()));
        }
      }

      return createTableNode;
    }
  }

  /**
   * convert table elements into Partition.
   *
   * @param context
   * @param expr
   * @return
   * @throws PlanningException
   */
  private PartitionDesc convertTableElementsPartition(PlanContext context,
                                                   CreateTable expr) throws PlanningException {
    Schema schema = convertTableElementsSchema(expr.getTableElements());
    PartitionDesc partitionDesc = null;
    List<Specifier> specifiers = null;
    if (expr.hasPartition()) {
      partitionDesc = new PartitionDesc();
      specifiers = TUtil.newList();

      partitionDesc.setPartitionsType(CatalogProtos.PartitionsType.valueOf(expr.getPartition()
          .getPartitionType().name()));

      if (expr.getPartition().getPartitionType().equals(PartitionType.HASH)) {
        CreateTable.HashPartition hashPartition = expr.getPartition();

        partitionDesc.setColumns(convertTableElementsColumns(expr.getTableElements()
            , hashPartition.getColumns()));

        if (hashPartition.getColumns() != null) {
          if (hashPartition.getQuantifier() != null) {
            String quantity = ((LiteralValue)hashPartition.getQuantifier()).getValue();
            partitionDesc.setNumPartitions(Integer.parseInt(quantity));
          }

          if (hashPartition.getSpecifiers() != null) {
            for(CreateTable.PartitionSpecifier eachSpec: hashPartition.getSpecifiers()) {
              specifiers.add(new Specifier(eachSpec.getName()));
            }
          }

          if (specifiers.isEmpty() && partitionDesc.getNumPartitions() > 0) {
            for (int i = 0; i < partitionDesc.getNumPartitions(); i++) {
              String partitionName = partitionDesc.getPartitionsType().name() + "_" + expr
                  .getTableName() + "_" + i;
              specifiers.add(new Specifier(partitionName));
            }
          }

          if (!specifiers.isEmpty())
            partitionDesc.setSpecifiers(specifiers);
        }
      } else if (expr.getPartition().getPartitionType().equals(PartitionType.LIST)) {
        CreateTable.ListPartition listPartition = expr.getPartition();

        partitionDesc.setColumns(convertTableElementsColumns(expr.getTableElements()
            , listPartition.getColumns()));

        if (listPartition.getSpecifiers() != null) {
          StringBuffer sb = new StringBuffer();

          for(CreateTable.ListPartitionSpecifier eachSpec: listPartition.getSpecifiers()) {
            Specifier specifier = new Specifier(eachSpec.getName());
            sb.delete(0, sb.length());
            for(Expr eachExpr : eachSpec.getValueList().getValues()) {
              context.block.setSchema(schema);
              EvalNode eval = createEvalTree(context.plan, context.block, eachExpr);
              if(sb.length() > 1)
                sb.append(",");

              sb.append(eval.toString());
            }
            specifier.setExpressions(sb.toString());
            specifiers.add(specifier);
          }
          if (!specifiers.isEmpty())
            partitionDesc.setSpecifiers(specifiers);
        }
      } else if (expr.getPartition().getPartitionType().equals(PartitionType.RANGE)) {
        CreateTable.RangePartition rangePartition = expr.getPartition();

        partitionDesc.setColumns(convertTableElementsColumns(expr.getTableElements()
            , rangePartition.getColumns()));

        if (rangePartition.getSpecifiers() != null) {
          for(CreateTable.RangePartitionSpecifier eachSpec: rangePartition.getSpecifiers()) {
            Specifier specifier = new Specifier();

            if (eachSpec.getName() != null)
              specifier.setName(eachSpec.getName());

            if (eachSpec.getEnd() != null) {
              context.block.setSchema(schema);
              EvalNode eval = createEvalTree(context.plan, context.block, eachSpec.getEnd());
              specifier.setExpressions(eval.toString());
            }

            if(eachSpec.isEndMaxValue()) {
              specifier.setExpressions(null);
            }
            specifiers.add(specifier);
          }
          if (!specifiers.isEmpty())
            partitionDesc.setSpecifiers(specifiers);
        }
      } else if (expr.getPartition().getPartitionType() == PartitionType.COLUMN) {
        ColumnPartition columnPartition = expr.getPartition();
        partitionDesc.setColumns(convertTableElementsSchema(columnPartition.getColumns()).getColumns());
        partitionDesc.setOmitValues(columnPartition.isOmitValues());
      }
    }

    return partitionDesc;
  }


  /**
   * It transforms table definition elements to schema.
   *
   * @param elements to be transformed
   * @return schema transformed from table definition elements
   */
  private Schema convertTableElementsSchema(CreateTable.ColumnDefinition [] elements) {
    Schema schema = new Schema();

    for (CreateTable.ColumnDefinition columnDefinition: elements) {
      schema.addColumn(convertColumn(columnDefinition));
    }

    return schema;
  }

  private ColumnDefinition[] convertSchemaToTableElements(Schema schema) {
    List<Column> columns = schema.getColumns();
    ColumnDefinition[] columnDefinitions = new ColumnDefinition[columns.size()];
    for(int i = 0; i < columns.size(); i ++) {
      Column col = columns.get(i);
      columnDefinitions[i] = new ColumnDefinition(col.getColumnName(), col.getDataType().getType().name());
    }

    return columnDefinitions;
  }

  private Collection<Column> convertTableElementsColumns(CreateTable.ColumnDefinition [] elements,
                                                   ColumnReferenceExpr[] references) {
    List<Column> columnList = TUtil.newList();

    for(CreateTable.ColumnDefinition columnDefinition: elements) {
      for(ColumnReferenceExpr eachReference: references) {
        if (columnDefinition.getColumnName().equalsIgnoreCase(eachReference.getName())) {
          columnList.add(convertColumn(columnDefinition));
        }
      }
    }

    return columnList;
  }

  private DataType convertDataType(DataTypeExpr dataType) {
    TajoDataTypes.Type type = TajoDataTypes.Type.valueOf(dataType.getTypeName());

    DataType.Builder builder = DataType.newBuilder();
    builder.setType(type);
    if (dataType.hasLengthOrPrecision()) {
      builder.setLength(dataType.getLengthOrPrecision());
    }
    return builder.build();
  }

  private Column convertColumn(ColumnDefinition columnDefinition) {
    return new Column(columnDefinition.getColumnName(), convertDataType(columnDefinition));
  }

  public LogicalNode visitInsert(PlanContext context, Stack<Expr> stack, Insert expr) throws PlanningException {
    stack.push(expr);
    QueryBlock newQueryBlock = context.plan.newNoNameBlock();
    PlanContext newContext = new PlanContext(context.plan, newQueryBlock);
    Stack<Expr> subStack = new Stack<Expr>();
    LogicalNode subQuery = visit(newContext, subStack, expr.getSubQuery());
    context.plan.connectBlocks(newQueryBlock, context.block, BlockType.TableSubQuery);
    stack.pop();

    InsertNode insertNode = null;
    if (expr.hasTableName()) {
      TableDesc desc = catalog.getTableDesc(expr.getTableName());
      context.block.addRelation(new ScanNode(context.plan.newPID(), desc));

      Schema targetSchema = new Schema();
      if (expr.hasTargetColumns()) {
        // INSERT OVERWRITE INTO TABLE tbl(col1 type, col2 type) SELECT ...
        String [] targetColumnNames = expr.getTargetColumns();
        for (int i = 0; i < targetColumnNames.length; i++) {
          Column targetColumn = context.plan.resolveColumn(context.block, null, new ColumnReferenceExpr(targetColumnNames[i]));
          targetSchema.addColumn(targetColumn);
        }
      } else {
        // use the output schema of select clause as target schema
        // if didn't specific target columns like the way below,
        // INSERT OVERWRITE INTO TABLE tbl SELECT ...
        Schema targetTableSchema = desc.getSchema();
        for (int i = 0; i < subQuery.getOutSchema().getColumnNum(); i++) {
          targetSchema.addColumn(targetTableSchema.getColumn(i));
        }
      }

      insertNode = new InsertNode(context.plan.newPID(), desc, subQuery);
      insertNode.setTargetSchema(targetSchema);
      insertNode.setOutSchema(targetSchema);
    }

    if (expr.hasLocation()) {
      insertNode = new InsertNode(context.plan.newPID(), new Path(expr.getLocation()), subQuery);
      if (expr.hasStorageType()) {
        insertNode.setStorageType(CatalogUtil.getStoreType(expr.getStorageType()));
      }
      if (expr.hasParams()) {
        Options options = new Options();
        options.putAll(expr.getParams());
        insertNode.setOptions(options);
      }
    }

    insertNode.setOverwrite(expr.isOverwrite());

    return insertNode;
  }

  @Override
  public LogicalNode visitDropTable(PlanContext context, Stack<Expr> stack, DropTable dropTable) {
    DropTableNode dropTableNode = new DropTableNode(context.plan.newPID(), dropTable.getTableName(),
        dropTable.isPurge());
    return dropTableNode;
  }

  public static int [] dateToIntArray(String years, String months, String days) 
    throws PlanningException { 
    int year = Integer.valueOf(years);
    int month = Integer.valueOf(months);
    int day = Integer.valueOf(days);

    if (!(1 <= year && year <= 9999)) {
      throw new PlanningException(String.format("Years (%d) must be between 1 and 9999 integer value", year));
    }

    if (!(1 <= month && month <= 12)) {
      throw new PlanningException(String.format("Months (%d) must be between 1 and 12 integer value", month));
    }

    if (!(1<= day && day <= 31)) {
      throw new PlanningException(String.format("Days (%d) must be between 1 and 31 integer value", day));
    }

    int [] results = new int[3];
    results[0] = year;
    results[1] = month;
    results[2] = day;

    return results;
  }

  public static int [] timeToIntArray(String hours, String minutes, String seconds, String fractionOfSecond) 
    throws PlanningException { 
    int hour = Integer.valueOf(hours);
    int minute = Integer.valueOf(minutes);
    int second = Integer.valueOf(seconds);
    int fraction = 0;
    if (fractionOfSecond != null) {
      fraction = Integer.valueOf(fractionOfSecond);
    }

    if (!(0 <= hour && hour <= 23)) {
      throw new PlanningException(String.format("Hours (%d) must be between 0 and 24 integer value", hour));
    }

    if (!(0 <= minute && minute <= 59)) {
      throw new PlanningException(String.format("Minutes (%d) must be between 0 and 59 integer value", minute));
    }

    if (!(0 <= second && second <= 59)) {
      throw new PlanningException(String.format("Seconds (%d) must be between 0 and 59 integer value", second));
    }

    if (fraction != 0) {
      if (!(0 <= fraction && fraction <= 999)) {
        throw new PlanningException(String.format("Seconds (%d) must be between 0 and 999 integer value", fraction));
      }
    }

    int [] results = new int[4];
    results[0] = hour;
    results[1] = minute;
    results[2] = second;
    results[3] = fraction;

    return results;
  }
    
  /*===============================================================================================
    Expression SECTION
   ===============================================================================================*/

  public EvalNode createEvalTree(LogicalPlan plan, QueryBlock block, final Expr expr)throws PlanningException {

    switch(expr.getType()) {
      // constants
      case NullLiteral:
        return new ConstEval(NullDatum.get());

      case Literal:
        LiteralValue literal = (LiteralValue) expr;
        switch (literal.getValueType()) {
          case Boolean:
            return new ConstEval(DatumFactory.createBool(((BooleanLiteral)literal).isTrue()));
          case String:
            return new ConstEval(DatumFactory.createText(literal.getValue()));
          case Unsigned_Integer:
            return new ConstEval(DatumFactory.createInt4(literal.getValue()));
          case Unsigned_Large_Integer:
            return new ConstEval(DatumFactory.createInt8(literal.getValue()));
          case Unsigned_Float:
            return new ConstEval(DatumFactory.createFloat8(literal.getValue()));
          default:
            throw new RuntimeException("Unsupported type: " + literal.getValueType());
        }

      case TimeLiteral: {
        TimeLiteral timeLiteral = (TimeLiteral) expr;
        TimeValue timeValue = timeLiteral.getTime();
        int [] times = LogicalPlanner.timeToIntArray(timeValue.getHours(),
                                         timeValue.getMinutes(),
                                         timeValue.getSeconds(),
                                         timeValue.getSecondsFraction());

        TimeDatum datum;
        if (timeValue.hasSecondsFraction()) {
          datum = new TimeDatum(times[0], times[1], times[2], times[3]);
        } else {
          datum = new TimeDatum(times[0], times[1], times[2]);
        }
        return new ConstEval(datum);
      }

      case TimestampLiteral: {
        TimestampLiteral timestampLiteral = (TimestampLiteral) expr;
        DateValue dateValue = timestampLiteral.getDate();
        TimeValue timeValue = timestampLiteral.getTime();

        int [] dates = LogicalPlanner.dateToIntArray(dateValue.getYears(),
                                        dateValue.getMonths(),
                                        dateValue.getDays());
        int [] times = LogicalPlanner.timeToIntArray(timeValue.getHours(),
                                        timeValue.getMinutes(),
                                        timeValue.getSeconds(),
                                        timeValue.getSecondsFraction());
        DateTime dateTime;
        if (timeValue.hasSecondsFraction()) {
          dateTime = new DateTime(dates[0], dates[1], dates[2], times[0], times[1], times[2], times[3]);
        } else {
          dateTime = new DateTime(dates[0], dates[1], dates[2], times[0], times[1], times[2]);
        }

        return new ConstEval(new TimestampDatum(dateTime));
      }

      case Sign:
        SignedExpr signedExpr = (SignedExpr) expr;
        EvalNode numericExpr = createEvalTree(plan, block, signedExpr.getChild());
        if (signedExpr.isNegative()) {
          return new SignedEval(signedExpr.isNegative(), numericExpr);
        } else {
          return numericExpr;
        }

      case Cast:
        CastExpr cast = (CastExpr) expr;
        return new CastEval(createEvalTree(plan, block, cast.getOperand()),
            convertDataType(cast.getTarget()));

      case ValueList: {
        ValueListExpr valueList = (ValueListExpr) expr;
        Datum[] values = new Datum[valueList.getValues().length];
        ConstEval [] constEvals = new ConstEval[valueList.getValues().length];
        for (int i = 0; i < valueList.getValues().length; i++) {
          constEvals[i] = (ConstEval) createEvalTree(plan, block, valueList.getValues()[i]);
          values[i] = constEvals[i].getValue();
        }
        return new RowConstantEval(values);
      }

        // unary expression
      case Not:
        NotExpr notExpr = (NotExpr) expr;
        return new NotEval(createEvalTree(plan, block, notExpr.getChild()));

      case Between: {
        BetweenPredicate between = (BetweenPredicate) expr;
        BetweenPredicateEval betweenEval = new BetweenPredicateEval(between.isNot(), between.isSymmetric(),
            createEvalTree(plan, block, between.predicand()), createEvalTree(plan, block, between.begin()),
            createEvalTree(plan, block, between.end()));
        return betweenEval;
      }
      // pattern matching predicates
      case LikePredicate:
      case SimilarToPredicate:
      case Regexp:
        PatternMatchPredicate patternMatch = (PatternMatchPredicate) expr;
        EvalNode field = createEvalTree(plan, block, patternMatch.getPredicand());
        ConstEval pattern = (ConstEval) createEvalTree(plan, block, patternMatch.getPattern());

        // A pattern is a const value in pattern matching predicates.
        // In a binary expression, the result is always null if a const value in left or right side is null.
        if (pattern.getValue() instanceof NullDatum) {
          return new ConstEval(NullDatum.get());
        } else {
          if (expr.getType() == OpType.LikePredicate) {
            return new LikePredicateEval(patternMatch.isNot(), field, pattern, patternMatch.isCaseInsensitive());
          } else if (expr.getType() == OpType.SimilarToPredicate) {
            return new SimilarToPredicateEval(patternMatch.isNot(), field, pattern);
          } else {
            return new RegexPredicateEval(patternMatch.isNot(), field, pattern, patternMatch.isCaseInsensitive());
          }
        }

      case InPredicate: {
        InPredicate inPredicate = (InPredicate) expr;
        FieldEval predicand =
            new FieldEval(plan.resolveColumn(block, null, (ColumnReferenceExpr) inPredicate.getPredicand()));
        RowConstantEval rowConstantEval = (RowConstantEval) createEvalTree(plan, block, inPredicate.getInValue());
        return new InEval(predicand, rowConstantEval, inPredicate.isNot());
      }

      case And:
      case Or:
      case Equals:
      case NotEquals:
      case LessThan:
      case LessThanOrEquals:
      case GreaterThan:
      case GreaterThanOrEquals:
      case Plus:
      case Minus:
      case Multiply:
      case Divide:
      case Modular:
      case Concatenate:
        BinaryOperator bin = (BinaryOperator) expr;
        return new BinaryEval(exprTypeToEvalType(expr.getType()),
            createEvalTree(plan, block, bin.getLeft()),
            createEvalTree(plan, block, bin.getRight()));

      // others
      case Column:
        return createFieldEval(plan, block, (ColumnReferenceExpr) expr);

      case CountRowsFunction: {
        FunctionDesc countRows = catalog.getFunction("count", FunctionType.AGGREGATION, new DataType[] {});

        try {
          block.setHasGrouping();

          return new AggregationFunctionCallEval(countRows, (AggFunction) countRows.newInstance(),
              new EvalNode[] {});
        } catch (InternalException e) {
          throw new UndefinedFunctionException(CatalogUtil.
              getCanonicalName(countRows.getSignature(), new DataType[]{}));
        }
      }
      case GeneralSetFunction: {
        GeneralSetFunctionExpr setFunction = (GeneralSetFunctionExpr) expr;
        Expr[] params = setFunction.getParams();
        EvalNode[] givenArgs = new EvalNode[params.length];
        DataType[] paramTypes = new DataType[params.length];

        FunctionType functionType = setFunction.isDistinct() ?
            FunctionType.DISTINCT_AGGREGATION : FunctionType.AGGREGATION;
        givenArgs[0] = createEvalTree(plan, block, params[0]);
        if (setFunction.getSignature().equalsIgnoreCase("count")) {
          paramTypes[0] = CatalogUtil.newSimpleDataType(TajoDataTypes.Type.ANY);
        } else {
          paramTypes[0] = givenArgs[0].getValueType();
        }

        if (!catalog.containFunction(setFunction.getSignature(), functionType, paramTypes)) {
          throw new UndefinedFunctionException(CatalogUtil. getCanonicalName(setFunction.getSignature(), paramTypes));
        }

        FunctionDesc funcDesc = catalog.getFunction(setFunction.getSignature(), functionType, paramTypes);
        if (!block.hasGroupbyNode()) {
          block.setHasGrouping();
        }
        try {
          return new AggregationFunctionCallEval(funcDesc, (AggFunction) funcDesc.newInstance(), givenArgs);
        } catch (InternalException e) {
          e.printStackTrace();
        }
      }
      break;

      case Function:
        FunctionExpr function = (FunctionExpr) expr;
        // Given parameters
        Expr[] params = function.getParams();
        if (params == null) {
            params = new Expr[1];
            params[0] = new NullLiteral();
        }

        EvalNode[] givenArgs = new EvalNode[params.length];
        DataType[] paramTypes = new DataType[params.length];

        for (int i = 0; i < params.length; i++) {
            givenArgs[i] = createEvalTree(plan, block, params[i]);
            paramTypes[i] = givenArgs[i].getValueType();
        }

        if (!catalog.containFunction(function.getSignature(), paramTypes)) {
            throw new UndefinedFunctionException(CatalogUtil.getCanonicalName(function.getSignature(), paramTypes));
        }

        FunctionDesc funcDesc = catalog.getFunction(function.getSignature(), paramTypes);

        try {

          FunctionType functionType = funcDesc.getFuncType();
          if (functionType == FunctionType.GENERAL || functionType == FunctionType.UDF) {
            return new GeneralFunctionEval(funcDesc, (GeneralFunction) funcDesc.newInstance(), givenArgs);
          } else if (functionType == FunctionType.AGGREGATION || functionType == FunctionType.UDA) {
            if (!block.hasGroupbyNode()) {
              block.setHasGrouping();
            }
            return new AggregationFunctionCallEval(funcDesc, (AggFunction) funcDesc.newInstance(), givenArgs);
          } else if (functionType == FunctionType.DISTINCT_AGGREGATION || functionType == FunctionType.DISTINCT_UDA) {
            throw new PlanningException("Unsupported function: " + funcDesc.toString());
          }
        } catch (InternalException e) {
          e.printStackTrace();
        }
        break;

      case CaseWhen:
        CaseWhenPredicate caseWhenExpr = (CaseWhenPredicate) expr;
        return createCaseWhenEval(plan, block, caseWhenExpr);

      case IsNullPredicate:
        IsNullPredicate nullPredicate = (IsNullPredicate) expr;
        return new IsNullEval(nullPredicate.isNot(),
            createEvalTree(plan, block, nullPredicate.getPredicand()));

      default:
    }
    return null;
  }

  private FieldEval createFieldEval(LogicalPlan plan, QueryBlock block,
                                    ColumnReferenceExpr columnRef) throws PlanningException {
    Column column = plan.resolveColumn(block, null, columnRef);
    return new FieldEval(column);
  }

  private static EvalType exprTypeToEvalType(OpType type) {
    switch (type) {
      case And: return EvalType.AND;
      case Or: return EvalType.OR;
      case Equals: return EvalType.EQUAL;
      case NotEquals: return EvalType.NOT_EQUAL;
      case LessThan: return EvalType.LTH;
      case LessThanOrEquals: return EvalType.LEQ;
      case GreaterThan: return EvalType.GTH;
      case GreaterThanOrEquals: return EvalType.GEQ;
      case Plus: return EvalType.PLUS;
      case Minus: return EvalType.MINUS;
      case Multiply: return EvalType.MULTIPLY;
      case Divide: return EvalType.DIVIDE;
      case Modular: return EvalType.MODULAR;
      case Concatenate: return EvalType.CONCATENATE;
      case Column: return EvalType.FIELD;
      case Function: return EvalType.FUNCTION;
      default: throw new RuntimeException("Unsupported type: " + type);
    }
  }

  public CaseWhenEval createCaseWhenEval(LogicalPlan plan, QueryBlock block,
                                              CaseWhenPredicate caseWhen) throws PlanningException {
    CaseWhenEval caseEval = new CaseWhenEval();
    EvalNode condition;
    EvalNode result;

    for (CaseWhenPredicate.WhenExpr when : caseWhen.getWhens()) {
      condition = createEvalTree(plan, block, when.getCondition());
      result = createEvalTree(plan, block, when.getResult());
      caseEval.addWhen(condition, result);
    }

    if (caseWhen.hasElseResult()) {
      caseEval.setElseResult(createEvalTree(plan, block, caseWhen.getElseResult()));
    }

    return caseEval;
  }

  Target[] annotateTargets(LogicalPlan plan, QueryBlock block, TargetExpr[] targets)
      throws PlanningException {
    Target annotatedTargets [] = new Target[targets.length];

    for (int i = 0; i < targets.length; i++) {
      annotatedTargets[i] = createTarget(plan, block, targets[i]);
    }
    return annotatedTargets;
  }

  Target createTarget(LogicalPlan plan, QueryBlock block,
                             TargetExpr target) throws PlanningException {
    if (target.hasAlias()) {
      return new Target(createEvalTree(plan, block, target.getExpr()),
          target.getAlias());
    } else {
      return new Target(createEvalTree(plan, block, target.getExpr()));
    }
  }

  /**
   * It transforms a list of targets to schema. If it contains anonymous targets, it names them.
   */
  static Schema getProjectedSchema(LogicalPlan plan, Target[] targets) {
    Schema projected = new Schema();
    for(Target t : targets) {
      DataType type = t.getEvalTree().getValueType();
      String name;
      if (t.hasAlias() || t.getEvalTree().getType() == EvalType.FIELD) {
        name = t.getCanonicalName();
      } else { // if an alias is not given or this target is an expression
        t.setAlias(plan.newNonameColumnName(t.getEvalTree().getName()));
        name = t.getAlias();
      }
      projected.addColumn(name,type);
    }

    return projected;
  }
}
